// The test-splitter tool fetches and runs test plans generated by Buildkite
// Test Splitting.
package main

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"os"
	"os/exec"
	"strconv"
	"time"

	"github.com/buildkite/test-splitter/internal/api"
	"github.com/buildkite/test-splitter/internal/config"
	"github.com/buildkite/test-splitter/internal/plan"
	"github.com/buildkite/test-splitter/internal/runner"
)

func main() {
	// TODO: detect test runner and use appropriate runner
	testRunner := runner.Rspec{}

	// get files
	fmt.Println("--- :test-analytics: Gathering test plan context and creating test plan request ğŸ¿ï¸")
	files, err := testRunner.GetFiles()
	if err != nil {
		log.Fatalf("Couldn't get files: %v", err)
	}
	fmt.Printf("Found %d files\n", len(files))

	// get config
	cfg, err := config.New()
	if err != nil {
		log.Fatal("Invalid configuration: ", err)
	}

	// get plan
	fmt.Println("--- :test-analytics: Getting Test Plan ğŸ£")
	fmt.Printf("config: %+v", cfg)

	testCases := []plan.TestCase{}
	for _, file := range files {
		testCases = append(testCases, plan.TestCase{
			Path: file,
		})
	}

	ctx := context.Background()
	// We expect the whole test plan fetching process takes no more than 60 seconds.
	// Configure the timeout as 70s to give it a bit more buffer.
	fetchCtx, cancel := context.WithTimeout(ctx, 70*time.Second)
	defer cancel()

	tests := plan.Tests{
		Cases:  testCases,
		Format: "files",
	}
	testPlan, err := api.FetchTestPlan(fetchCtx, cfg.ServerBaseUrl, api.TestPlanParams{
		SuiteToken:  cfg.SuiteToken,
		Mode:        cfg.Mode,
		Identifier:  cfg.Identifier,
		Parallelism: cfg.Parallelism,
		Tests:       tests,
	})
	if err != nil {
		// Didn't exceed context deadline? Must have been some kind of error that
		// means we should abort.
		if !errors.Is(err, context.DeadlineExceeded) {
			log.Fatalf("Couldn't fetch test plan: %v", err)
		}
		// Create the fallback plan
		testPlan = plan.CreateFallbackPlan(tests, cfg.Parallelism)
	}

	// The server can return an "error" plan indicated by an empty task list (i.e. `{"tasks": {}}`).
	// In this case, we should create a fallback plan.
	if len(testPlan.Tasks) == 0 {
		testPlan = plan.CreateFallbackPlan(tests, cfg.Parallelism)
	}

	// get plan for this node
	thisNodeTask := testPlan.Tasks[strconv.Itoa(cfg.NodeIndex)]

	prettifiedPlan, _ := json.MarshalIndent(thisNodeTask, "", "  ")
	fmt.Println("--- :test-analytics: Plan for this node ğŸŠ")
	fmt.Println(string(prettifiedPlan))

	// execute tests
	runnableTests := []string{}
	for _, testCase := range thisNodeTask.Tests.Cases {
		runnableTests = append(runnableTests, testCase.Path)
	}
	if err := testRunner.Run(runnableTests); err != nil {
		if exitError := new(exec.ExitError); errors.As(err, &exitError) {
			exitCode := exitError.ExitCode()
			log.Printf("Rspec exited with error %d", exitCode)
			os.Exit(exitCode)
		}
		log.Fatalf("Couldn't run tests: %v", err)
	}

	fmt.Println("--- :test-analytics: Test execution results ğŸ“Š")
	err = testRunner.Report(os.Stdout, thisNodeTask.Tests.Cases)
	if err != nil {
		fmt.Println(err)
	}
}
